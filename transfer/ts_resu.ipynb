{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dde6e47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.10.0+cu113\n",
      "Torchvision Version:  0.11.1+cu113\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 22 20:18:19 2021\n",
    "\n",
    "@author: xuquanfeng\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets,transforms,utils,models\n",
    "from VAE_model.models import VAE, MyDataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from astropy.io import fits\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "#设置随机种子\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "setup_seed(10)\n",
    "# Hyper parameters\n",
    "if not os.path.exists('./model'):\n",
    "    os.mkdir('./model')\n",
    "if not os.path.exists('./train_proces'):\n",
    "    os.mkdir('./train_proces')\n",
    "num_epochs = 20   #循环次数\n",
    "batch_size = 128    #每次投喂数据量\n",
    "learning_rate = 0.00001   #学习率\n",
    "num_var = 40\n",
    "momentum = 0.8\n",
    "k = 1\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = torch.load('/data/xqf/VAE2/model/vae_40_best_1.pth')\n",
    "\n",
    "# print(model)\n",
    "# Device configuration  判断能否使用cuda加速\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + k*KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a76b28d-df13-4c1b-ac16-1f40f39cc0ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3434 (0%)] Loss: 5224.282715 time:2.00s\n",
      "Train Epoch: 0 [1280/3434 (37%)] Loss: 2338.234131 time:4.00s\n",
      "Train Epoch: 0 [2560/3434 (74%)] Loss: 2774.618164 time:6.00s\n",
      "====> Epoch: 0 Average loss: 3671.7266\n",
      "Train Epoch: 1 [0/3434 (0%)] Loss: 3200.620361 time:10.00s\n",
      "Train Epoch: 1 [1280/3434 (37%)] Loss: 2973.047607 time:12.00s\n",
      "Train Epoch: 1 [2560/3434 (74%)] Loss: 3868.409912 time:14.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 1 Average loss: 3288.7866\n",
      "Train Epoch: 2 [0/3434 (0%)] Loss: 2168.843262 time:18.00s\n",
      "Train Epoch: 2 [1280/3434 (37%)] Loss: 2138.315186 time:20.00s\n",
      "Train Epoch: 2 [2560/3434 (74%)] Loss: 2974.541504 time:22.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 2 Average loss: 3156.9852\n",
      "Train Epoch: 3 [0/3434 (0%)] Loss: 2326.603760 time:26.00s\n",
      "Train Epoch: 3 [1280/3434 (37%)] Loss: 3571.593018 time:28.00s\n",
      "Train Epoch: 3 [2560/3434 (74%)] Loss: 4088.355957 time:30.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 3 Average loss: 2988.3582\n",
      "Train Epoch: 4 [0/3434 (0%)] Loss: 4365.952637 time:34.00s\n",
      "Train Epoch: 4 [1280/3434 (37%)] Loss: 3815.220459 time:36.00s\n",
      "Train Epoch: 4 [2560/3434 (74%)] Loss: 3335.202148 time:38.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 4 Average loss: 2895.0506\n",
      "Train Epoch: 5 [0/3434 (0%)] Loss: 3454.443848 time:43.00s\n",
      "Train Epoch: 5 [1280/3434 (37%)] Loss: 3163.930664 time:45.00s\n",
      "Train Epoch: 5 [2560/3434 (74%)] Loss: 3332.972656 time:47.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 5 Average loss: 2805.1460\n",
      "Train Epoch: 6 [0/3434 (0%)] Loss: 2586.550781 time:50.00s\n",
      "Train Epoch: 6 [1280/3434 (37%)] Loss: 1841.157471 time:52.00s\n",
      "Train Epoch: 6 [2560/3434 (74%)] Loss: 4122.132812 time:55.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 6 Average loss: 2791.3678\n",
      "Train Epoch: 7 [0/3434 (0%)] Loss: 2994.284180 time:58.00s\n",
      "Train Epoch: 7 [1280/3434 (37%)] Loss: 2164.106934 time:61.00s\n",
      "Train Epoch: 7 [2560/3434 (74%)] Loss: 3115.039062 time:63.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 7 Average loss: 2779.9828\n",
      "Train Epoch: 8 [0/3434 (0%)] Loss: 1981.080078 time:67.00s\n",
      "Train Epoch: 8 [1280/3434 (37%)] Loss: 2587.295898 time:69.00s\n",
      "Train Epoch: 8 [2560/3434 (74%)] Loss: 3702.741943 time:71.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 8 Average loss: 2735.4346\n",
      "Train Epoch: 9 [0/3434 (0%)] Loss: 3673.835938 time:75.00s\n",
      "Train Epoch: 9 [1280/3434 (37%)] Loss: 3347.859863 time:77.00s\n",
      "Train Epoch: 9 [2560/3434 (74%)] Loss: 2880.389648 time:79.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 9 Average loss: 2722.6169\n",
      "Train Epoch: 10 [0/3434 (0%)] Loss: 3202.786621 time:83.00s\n",
      "Train Epoch: 10 [1280/3434 (37%)] Loss: 2424.922607 time:85.00s\n",
      "Train Epoch: 10 [2560/3434 (74%)] Loss: 2597.205811 time:87.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 10 Average loss: 2694.9898\n",
      "Train Epoch: 11 [0/3434 (0%)] Loss: 2847.502441 time:91.00s\n",
      "Train Epoch: 11 [1280/3434 (37%)] Loss: 2771.113281 time:93.00s\n",
      "Train Epoch: 11 [2560/3434 (74%)] Loss: 2209.266357 time:95.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 11 Average loss: 2624.9683\n",
      "Train Epoch: 12 [0/3434 (0%)] Loss: 2373.590088 time:99.00s\n",
      "Train Epoch: 12 [1280/3434 (37%)] Loss: 2005.020630 time:101.00s\n",
      "Train Epoch: 12 [2560/3434 (74%)] Loss: 1635.279541 time:103.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 12 Average loss: 2589.9671\n",
      "Train Epoch: 13 [0/3434 (0%)] Loss: 2696.375244 time:107.00s\n",
      "Train Epoch: 13 [1280/3434 (37%)] Loss: 2258.886963 time:109.00s\n",
      "Train Epoch: 13 [2560/3434 (74%)] Loss: 2263.734863 time:111.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 13 Average loss: 2516.1009\n",
      "Train Epoch: 14 [0/3434 (0%)] Loss: 1835.080078 time:115.00s\n",
      "Train Epoch: 14 [1280/3434 (37%)] Loss: 3882.374512 time:117.00s\n",
      "Train Epoch: 14 [2560/3434 (74%)] Loss: 4075.356689 time:119.00s\n",
      "====> Epoch: 14 Average loss: 2520.6284\n",
      "Train Epoch: 15 [0/3434 (0%)] Loss: 2259.687012 time:123.00s\n",
      "Train Epoch: 15 [1280/3434 (37%)] Loss: 2153.792480 time:125.00s\n",
      "Train Epoch: 15 [2560/3434 (74%)] Loss: 2014.731323 time:127.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 15 Average loss: 2496.1343\n",
      "Train Epoch: 16 [0/3434 (0%)] Loss: 2564.765137 time:130.00s\n",
      "Train Epoch: 16 [1280/3434 (37%)] Loss: 2552.364258 time:132.00s\n",
      "Train Epoch: 16 [2560/3434 (74%)] Loss: 2493.098877 time:135.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 16 Average loss: 2486.8676\n",
      "Train Epoch: 17 [0/3434 (0%)] Loss: 2171.525391 time:138.00s\n",
      "Train Epoch: 17 [1280/3434 (37%)] Loss: 2778.847168 time:140.00s\n",
      "Train Epoch: 17 [2560/3434 (74%)] Loss: 2371.101074 time:142.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 17 Average loss: 2462.4820\n",
      "Train Epoch: 18 [0/3434 (0%)] Loss: 2916.021729 time:146.00s\n",
      "Train Epoch: 18 [1280/3434 (37%)] Loss: 1905.607788 time:148.00s\n",
      "Train Epoch: 18 [2560/3434 (74%)] Loss: 1499.278320 time:150.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 18 Average loss: 2380.9343\n",
      "Train Epoch: 19 [0/3434 (0%)] Loss: 3003.958740 time:154.00s\n",
      "Train Epoch: 19 [1280/3434 (37%)] Loss: 1753.093872 time:156.00s\n",
      "Train Epoch: 19 [2560/3434 (74%)] Loss: 2045.947998 time:158.00s\n",
      "====> Epoch: 19 Average loss: 2384.5946\n"
     ]
    }
   ],
   "source": [
    "train_loss11 = open('./train_proces/train_'+str(num_var)+'_'+str(k)+'.txt', 'w')\n",
    "train_data = MyDataset(datatxt='train_t.txt', transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=True,num_workers=20)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "strattime = datetime.datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img,fn = data\n",
    "        img = Variable(img)\n",
    "        img = img.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        # train_loss += loss.data[0]\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            endtime = datetime.datetime.now()\n",
    "            asd = str('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} time:{:.2f}s'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(img),\n",
    "                (endtime-strattime).seconds))\n",
    "            print(asd)\n",
    "            train_loss11.write(asd+'\\n')\n",
    "            # torch.save(model, './model/b_vae'+str(epoch)+'_'+str(batch_idx)+'.pth')\n",
    "    if epoch == 0:\n",
    "        best_loss = train_loss / len(train_loader.dataset)\n",
    "    if epoch > 0 and best_loss > train_loss / len(train_loader.dataset):\n",
    "        best_loss = train_loss / len(train_loader.dataset)\n",
    "        asds = 'Save Best Model!'\n",
    "        print(asds)\n",
    "        train_loss11.write(asds+'\\n')\n",
    "        torch.save(model, './model/vae_'+str(num_var)+'_'+str(k)+'_best.pth')\n",
    "    asds = str('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))\n",
    "    print(asds)\n",
    "    train_loss11.write(asds+'\\n')\n",
    "train_loss11.close()\n",
    "# if epoch == num_epochs-1:\n",
    "#     torch.save(model, './model/vae_'+str(num_var)+'_'+str(k)+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e494c9-5898-4992-a3ff-b686d734aa54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3434\n"
     ]
    }
   ],
   "source": [
    "train_data = MyDataset(datatxt='train_t1.txt', transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=False,num_workers=20)\n",
    "\n",
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('./result')\n",
    "model.eval()\n",
    "from tqdm import tqdm\n",
    "sssi = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "        img,fn = data\n",
    "        img = Variable(img)\n",
    "        img = img.to(device)\n",
    "        mu, logvar = model.encode(img)\n",
    "\n",
    "        yunatu = img.cpu().numpy()\n",
    "        for i in range(len(yunatu)):\n",
    "            qw = [fn[i]]\n",
    "            qw.extend(mu[i].cpu().detach().numpy())\n",
    "            sssi.append(qw)\n",
    "\n",
    "    dd = np.array(sssi)\n",
    "    print(len(dd))\n",
    "    # np.save(pt+'result_ssim.npy',dd)\n",
    "    np.save('./result/resu_'+str(num_var)+'_'+str(k)+'_in_no.npy',dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6004a72f-90e6-45cf-81cc-b2cb260baef5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3434, 41)\n",
      "[['/data/GZ_Decals/MGS_out_DECaLS/175.89149808110213_21.67228737779398_0.262_grz_.fits'\n",
      "  '-0.2395398' '0.30021068' ... '0.03285286' '-0.15634988' '0.2659969']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/176.1464259029576_6.42738628465911_0.262_grz_.fits'\n",
      "  '0.06613478' '-0.045190185' ... '0.25628704' '-0.060526717'\n",
      "  '-0.6036183']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/216.73248662726843_-2.558336707515353_0.262_grz_.fits'\n",
      "  '5.0170693' '3.13536' ... '-1.669854' '-0.7415669' '3.479699']\n",
      " ...\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/185.8959342163261_12.898011042802942_0.262_grz_.fits'\n",
      "  '4.595039' '0.9067448' ... '-2.7144554' '-8.880546' '-2.725317']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/130.09162761307095_27.113144869991118_0.262_grz_.fits'\n",
      "  '0.1841171' '-0.02502913' ... '0.4120853' '0.27991506' '0.40033835']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/209.69722323971683_-2.796119143808119_0.262_grz_.fits'\n",
      "  '0.89246887' '-2.2485366' ... '-0.73100126' '0.91381544' '1.7066566']]\n"
     ]
    }
   ],
   "source": [
    "print(dd.shape)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1da342-b09e-45b6-b64b-b2706d874794",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3434, 41)\n",
      "[['/data/GZ_Decals/MGS_out_DECaLS/175.89149808110213_21.67228737779398_0.262_grz_.fits'\n",
      "  '-0.28436983' '0.30952153' ... '0.030438695' '-0.17496628' '0.2859994']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/176.1464259029576_6.42738628465911_0.262_grz_.fits'\n",
      "  '-0.04641933' '0.2062142' ... '0.25107816' '-0.08299783' '-0.62852347']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/216.73248662726843_-2.558336707515353_0.262_grz_.fits'\n",
      "  '6.4118094' '4.4545727' ... '-2.5403154' '0.4222854' '3.94778']\n",
      " ...\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/185.8959342163261_12.898011042802942_0.262_grz_.fits'\n",
      "  '4.196303' '1.0886736' ... '-1.9845552' '-7.5776615' '0.40705034']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/130.09162761307095_27.113144869991118_0.262_grz_.fits'\n",
      "  '0.29514536' '0.16261218' ... '0.36543643' '0.21575616' '0.37621558']\n",
      " ['/data/GZ_Decals/MGS_out_DECaLS/209.69722323971683_-2.796119143808119_0.262_grz_.fits'\n",
      "  '1.0389524' '-2.2737217' ... '-0.7585088' '0.94853944' '1.6581957']]\n"
     ]
    }
   ],
   "source": [
    "print(dd.shape)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf66bd59-10d7-4c05-9a93-ec011bfd419a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3434, 41)\n",
      "[['/data/GZ_Decals/nomerge/175.8905862789053_21.66981935317594_0.fits'\n",
      "  '0.006995933' '1.0993093' ... '0.3568548' '-0.008556896' '0.49385735']\n",
      " ['/data/GZ_Decals/nomerge/176.14777944132385_6.43021218747715_0.fits'\n",
      "  '-0.45819253' '0.1510943' ... '-0.019727178' '-0.26700974' '0.3930761']\n",
      " ['/data/GZ_Decals/nomerge/216.73420321996912_-2.5567049269072277_0.fits'\n",
      "  '-3.1298068' '-0.26893172' ... '1.1139963' '1.4247977' '4.353631']\n",
      " ...\n",
      " ['/data/GZ_Decals/nomerge/185.89469726554452_12.897557445261423_0.fits'\n",
      "  '0.84842736' '0.8459865' ... '-6.7031136' '-3.6388366' '5.3683214']\n",
      " ['/data/GZ_Decals/nomerge/130.09191714259262_27.113977190304865_0.fits'\n",
      "  '-0.36364064' '0.03688038' ... '0.25311407' '0.038813382' '0.21880837']\n",
      " ['/data/GZ_Decals/nomerge/209.6963186915605_-2.794944672696973_0.fits'\n",
      "  '-0.8575084' '-0.14070234' ... '0.79517335' '-0.75291526' '1.2931647']]\n"
     ]
    }
   ],
   "source": [
    "print(dd.shape)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0e5ab-f728-4c97-887f-b0aa1c96e0bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}