{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dde6e47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.10.0+cu113\n",
      "Torchvision Version:  0.11.1+cu113\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 22 20:18:19 2021\n",
    "\n",
    "@author: xuquanfeng\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets,transforms,utils,models\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from astropy.io import fits\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "#设置随机种子\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "setup_seed(10)\n",
    "# Hyper parameters\n",
    "if not os.path.exists('./model'):\n",
    "    os.mkdir('./model')\n",
    "if not os.path.exists('./train_proces'):\n",
    "    os.mkdir('./train_proces')\n",
    "num_epochs = 20   #循环次数\n",
    "batch_size = 128    #每次投喂数据量\n",
    "learning_rate = 0.00001   #学习率\n",
    "num_var = 40\n",
    "momentum = 0.8\n",
    "k = 1\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, datatxt, transform=None, target_transform=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        fh = open(datatxt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            words = line.rstrip().split()\n",
    "            imgs.append((words[0],words[1]))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):  # 这个方法是必须要有的，用于按照索引读取每个元素的具体内容\n",
    "        fn = self.imgs[index]  # fn是图片path #fn和label分别获得imgs[index]也即是刚才每行中word[0]和word[1]的信息\n",
    "        hdu = fits.open(fn[0])\n",
    "        img = hdu[0].data\n",
    "        img = np.array(img,dtype=np.float32)\n",
    "        hdu.close()\n",
    "        hdu = fits.open(fn[1])\n",
    "        oimg = hdu[0].data\n",
    "        oimg = np.array(oimg,dtype=np.float32)\n",
    "        hdu.close()\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            img = img.permute(1,0,2)\n",
    "            oimg = self.transform(oimg)\n",
    "            oimg = oimg.permute(1,0,2)\n",
    "        return img,oimg,fn\n",
    "    def __len__(self):  # 这个函数也必须要写，它返回的是数据集的长度，也就是多少张图片，要和loader的长度作区分\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,num_var):\n",
    "        super(VAE, self).__init__()\n",
    "        modules = []\n",
    "        hidden_dims = [32, 64, 128]\n",
    "        self.hidden_dims = hidden_dims\n",
    "        in_channels = 3\n",
    "        latent_dim = num_var\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    # nn.BatchNorm2d(h_dim),\n",
    "                    nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2),return_indices=True),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1]*16, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1]*16, latent_dim)\n",
    "        \n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 16)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.MaxUnpool2d((2, 2), stride=(2, 2)),\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    # nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.MaxUnpool2d((2, 2), stride=(2, 2)),\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            # nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.ReLU())\n",
    "\n",
    "    def encode(self, x):\n",
    "        result = x\n",
    "        idx = []\n",
    "        for i in range(len(self.hidden_dims)):\n",
    "            result,indices = self.encoder[i][:2](result)\n",
    "            idx.append(indices)\n",
    "            result = self.encoder[i][2](result)        \n",
    "        self.idx = idx\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.FloatTensor(std.size()).normal_().to(device)\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(len(result), 128, 4, 4)\n",
    "        for i in range(len(self.hidden_dims)-1):\n",
    "            result = self.decoder[i][0](result,self.idx[len(self.hidden_dims)-1-i])\n",
    "            result = self.decoder[i][1:](result)\n",
    "        # result = self.decoder(result)\n",
    "        result = self.final_layer[0](result,self.idx[0])\n",
    "        result = self.final_layer[1:](result)\n",
    "        return result\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(len(x),-1)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "torch.cuda.empty_cache()\n",
    "model = torch.load('/data/xqf/VAE2/model/vae_40_best.pth')\n",
    "\n",
    "# print(model)\n",
    "# Device configuration  判断能否使用cuda加速\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cc1eb04-7e97-4109-86b5-054e3188b35a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _fspecial_gauss_1d(size, sigma):\n",
    "    coords = torch.arange(size).to(dtype=torch.float)\n",
    "    coords -= size//2\n",
    "    g = torch.exp(-(coords**2) / (2*sigma**2))\n",
    "    g /= g.sum()\n",
    "    return g.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "def gaussian_filter(input, win):\n",
    "    N, C, H, W = input.shape\n",
    "    out = F.conv2d(input, win, stride=1, padding=0, groups=C)\n",
    "    out = F.conv2d(out, win.transpose(2, 3), stride=1, padding=0, groups=C)\n",
    "    return out\n",
    "\n",
    "def _ssim(X, Y, win, data_range=1023, size_average=True, full=False):\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    batch, channel, height, width = X.shape\n",
    "    compensation = 1.0\n",
    "\n",
    "    C1 = (K1 * data_range)**2\n",
    "    C2 = (K2 * data_range)**2\n",
    "\n",
    "    win = win.to(X.device, dtype=X.dtype)\n",
    "\n",
    "    mu1 = gaussian_filter(X, win)\n",
    "    mu2 = gaussian_filter(Y, win)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = compensation * ( gaussian_filter(X * X, win) - mu1_sq )\n",
    "    sigma2_sq = compensation * ( gaussian_filter(Y * Y, win) - mu2_sq )\n",
    "    sigma12   = compensation * ( gaussian_filter(X * Y, win) - mu1_mu2 )\n",
    "\n",
    "    cs_map = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1)) * cs_map\n",
    "\n",
    "    if size_average:\n",
    "        ssim_val = ssim_map.mean()\n",
    "        cs = cs_map.mean()\n",
    "    else:\n",
    "        ssim_val = ssim_map.mean(-1).mean(-1).mean(-1)  # reduce along CHW\n",
    "        cs = cs_map.mean(-1).mean(-1).mean(-1)\n",
    "\n",
    "    if full:\n",
    "        return ssim_val, cs\n",
    "    else:\n",
    "        return ssim_val\n",
    "\n",
    "def ssim(X, Y, win_size=11, win_sigma=10, win=None, data_range=1, size_average=True, full=False):\n",
    "\n",
    "    if len(X.shape) != 4:\n",
    "        raise ValueError('Input images must 4-d tensor.')\n",
    "\n",
    "    if not X.type() == Y.type():\n",
    "        raise ValueError('Input images must have the same dtype.')\n",
    "\n",
    "    if not X.shape == Y.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "\n",
    "    if not (win_size % 2 == 1):\n",
    "        raise ValueError('Window size must be odd.')\n",
    "\n",
    "    win_sigma = win_sigma\n",
    "    if win is None:\n",
    "        win = _fspecial_gauss_1d(win_size, win_sigma)\n",
    "        win = win.repeat(X.shape[1], 1, 1, 1)\n",
    "    else:\n",
    "        win_size = win.shape[-1]\n",
    "\n",
    "    ssim_val, cs = _ssim(X, Y,\n",
    "                         win=win,\n",
    "                         data_range=data_range,\n",
    "                         size_average=False,\n",
    "                         full=True)\n",
    "    if size_average:\n",
    "        ssim_val = ssim_val.mean()\n",
    "        cs = cs.mean()\n",
    "\n",
    "    if full:\n",
    "        return ssim_val, cs\n",
    "    else:\n",
    "        return ssim_val\n",
    "\n",
    "\n",
    "    def __init__(self, win_size=11, win_sigma=1.5, data_range=255, size_average=True, channel=3, weights=None):\n",
    "        super(MS_SSIM, self).__init__()\n",
    "        self.win = _fspecial_gauss_1d(\n",
    "            win_size, win_sigma).repeat(channel, 1, 1, 1)\n",
    "        self.size_average = size_average\n",
    "        self.data_range = data_range\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return ms_ssim(X, Y, win=self.win, size_average=self.size_average, data_range=self.data_range, weights=self.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e494c9-5898-4992-a3ff-b686d734aa54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:14<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3434\n"
     ]
    }
   ],
   "source": [
    "train_data = MyDataset(datatxt='train_tal.txt', transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=False,num_workers=20)\n",
    "\n",
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('./result')\n",
    "model.eval()\n",
    "from tqdm import tqdm\n",
    "sssi = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "        img,oimg,fn = data\n",
    "        img = Variable(img)\n",
    "        img = img.to(device)\n",
    "        oimg = Variable(oimg)\n",
    "        oimg = oimg.to(device)\n",
    "        \n",
    "        cimg, mu, lov = model(img)\n",
    "        ocimg, omu, olov = model(oimg)\n",
    "\n",
    "        for i in range(len(img)):\n",
    "            ssim_val = ssim(img[i].unsqueeze(0), cimg[i].unsqueeze(0), data_range=1, size_average=True,)\n",
    "            qw = [fn[0][i]]\n",
    "            qw.append(ssim_val.cpu().detach().numpy())\n",
    "            qw.extend(mu[i].cpu().detach().numpy())\n",
    "            qw.append(fn[1][i])\n",
    "            ssim_val = ssim(oimg[i].unsqueeze(0), ocimg[i].unsqueeze(0), data_range=1, size_average=True,)\n",
    "            qw.append(ssim_val.cpu().detach().numpy())\n",
    "            qw.extend(omu[i].cpu().detach().numpy())\n",
    "            sssi.append(qw)\n",
    "\n",
    "    dd = np.array(sssi)\n",
    "    print(len(dd))\n",
    "    # np.save(pt+'result_ssim.npy',dd)\n",
    "    np.save('./result/notf_resu_'+str(num_var)+'_'+str(k)+'_all.npy',dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac87a1-83ff-4fe4-8401-62b8e6cc8ca1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}