{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dde6e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.10.0+cu113\n",
      "Torchvision Version:  0.11.1+cu113\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 22 20:18:19 2021\n",
    "\n",
    "@author: xuquanfeng\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets,transforms,utils,models\n",
    "from VAE_model.models import VAE, MyDataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from astropy.io import fits\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "#设置随机种子\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "setup_seed(10)\n",
    "# Hyper parameters\n",
    "if not os.path.exists('./model'):\n",
    "    os.mkdir('./model')\n",
    "if not os.path.exists('./train_proces'):\n",
    "    os.mkdir('./train_proces')\n",
    "num_epochs = 20   #循环次数\n",
    "batch_size = 128    #每次投喂数据量\n",
    "learning_rate = 0.00001   #学习率\n",
    "num_var = 40\n",
    "momentum = 0.8\n",
    "k = 1\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = torch.load('/data/xqf/VAE1/model/vae_40_best.pth')\n",
    "\n",
    "# print(model)\n",
    "# Device configuration  判断能否使用cuda加速\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + k*KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a76b28d-df13-4c1b-ac16-1f40f39cc0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3434 (0%)] Loss: 133.776917 time:3.00s\n",
      "Train Epoch: 0 [1280/3434 (37%)] Loss: 108.219086 time:4.00s\n",
      "Train Epoch: 0 [2560/3434 (74%)] Loss: 87.625175 time:6.00s\n",
      "====> Epoch: 0 Average loss: 103.7544\n",
      "Train Epoch: 1 [0/3434 (0%)] Loss: 82.926041 time:9.00s\n",
      "Train Epoch: 1 [1280/3434 (37%)] Loss: 60.190437 time:11.00s\n",
      "Train Epoch: 1 [2560/3434 (74%)] Loss: 50.859272 time:13.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 1 Average loss: 54.6232\n",
      "Train Epoch: 2 [0/3434 (0%)] Loss: 46.501923 time:17.00s\n",
      "Train Epoch: 2 [1280/3434 (37%)] Loss: 31.053101 time:19.00s\n",
      "Train Epoch: 2 [2560/3434 (74%)] Loss: 26.530066 time:20.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 2 Average loss: 33.2189\n",
      "Train Epoch: 3 [0/3434 (0%)] Loss: 23.385735 time:24.00s\n",
      "Train Epoch: 3 [1280/3434 (37%)] Loss: 22.692348 time:26.00s\n",
      "Train Epoch: 3 [2560/3434 (74%)] Loss: 20.756224 time:27.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 3 Average loss: 23.0032\n",
      "Train Epoch: 4 [0/3434 (0%)] Loss: 14.030273 time:31.00s\n",
      "Train Epoch: 4 [1280/3434 (37%)] Loss: 18.811657 time:33.00s\n",
      "Train Epoch: 4 [2560/3434 (74%)] Loss: 13.652113 time:34.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 4 Average loss: 16.7678\n",
      "Train Epoch: 5 [0/3434 (0%)] Loss: 12.321404 time:38.00s\n",
      "Train Epoch: 5 [1280/3434 (37%)] Loss: 14.548686 time:40.00s\n",
      "Train Epoch: 5 [2560/3434 (74%)] Loss: 12.150709 time:42.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 5 Average loss: 13.3860\n",
      "Train Epoch: 6 [0/3434 (0%)] Loss: 8.315304 time:46.00s\n",
      "Train Epoch: 6 [1280/3434 (37%)] Loss: 9.890808 time:48.00s\n",
      "Train Epoch: 6 [2560/3434 (74%)] Loss: 9.530516 time:49.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 6 Average loss: 10.7953\n",
      "Train Epoch: 7 [0/3434 (0%)] Loss: 14.387720 time:53.00s\n",
      "Train Epoch: 7 [1280/3434 (37%)] Loss: 10.381603 time:55.00s\n",
      "Train Epoch: 7 [2560/3434 (74%)] Loss: 6.497911 time:56.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 7 Average loss: 8.8102\n",
      "Train Epoch: 8 [0/3434 (0%)] Loss: 5.445970 time:60.00s\n",
      "Train Epoch: 8 [1280/3434 (37%)] Loss: 6.804548 time:62.00s\n",
      "Train Epoch: 8 [2560/3434 (74%)] Loss: 4.942215 time:64.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 8 Average loss: 7.6619\n",
      "Train Epoch: 9 [0/3434 (0%)] Loss: 5.518306 time:68.00s\n",
      "Train Epoch: 9 [1280/3434 (37%)] Loss: 4.590852 time:69.00s\n",
      "Train Epoch: 9 [2560/3434 (74%)] Loss: 5.020246 time:71.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 9 Average loss: 6.4931\n",
      "Train Epoch: 10 [0/3434 (0%)] Loss: 6.789507 time:75.00s\n",
      "Train Epoch: 10 [1280/3434 (37%)] Loss: 6.063695 time:77.00s\n",
      "Train Epoch: 10 [2560/3434 (74%)] Loss: 3.484003 time:78.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 10 Average loss: 5.6143\n",
      "Train Epoch: 11 [0/3434 (0%)] Loss: 5.943000 time:82.00s\n",
      "Train Epoch: 11 [1280/3434 (37%)] Loss: 3.869010 time:84.00s\n",
      "Train Epoch: 11 [2560/3434 (74%)] Loss: 3.442996 time:85.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 11 Average loss: 5.1796\n",
      "Train Epoch: 12 [0/3434 (0%)] Loss: 4.458745 time:90.00s\n",
      "Train Epoch: 12 [1280/3434 (37%)] Loss: 5.663193 time:91.00s\n",
      "Train Epoch: 12 [2560/3434 (74%)] Loss: 4.187687 time:93.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 12 Average loss: 4.4631\n",
      "Train Epoch: 13 [0/3434 (0%)] Loss: 6.226319 time:97.00s\n",
      "Train Epoch: 13 [1280/3434 (37%)] Loss: 3.097163 time:99.00s\n",
      "Train Epoch: 13 [2560/3434 (74%)] Loss: 2.680000 time:100.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 13 Average loss: 3.9613\n",
      "Train Epoch: 14 [0/3434 (0%)] Loss: 5.854977 time:105.00s\n",
      "Train Epoch: 14 [1280/3434 (37%)] Loss: 2.896060 time:106.00s\n",
      "Train Epoch: 14 [2560/3434 (74%)] Loss: 3.002541 time:108.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 14 Average loss: 3.7232\n",
      "Train Epoch: 15 [0/3434 (0%)] Loss: 3.756187 time:111.00s\n",
      "Train Epoch: 15 [1280/3434 (37%)] Loss: 3.856591 time:113.00s\n",
      "Train Epoch: 15 [2560/3434 (74%)] Loss: 2.840927 time:115.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 15 Average loss: 3.3352\n",
      "Train Epoch: 16 [0/3434 (0%)] Loss: 4.379735 time:119.00s\n",
      "Train Epoch: 16 [1280/3434 (37%)] Loss: 2.328732 time:121.00s\n",
      "Train Epoch: 16 [2560/3434 (74%)] Loss: 3.351640 time:122.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 16 Average loss: 3.1952\n",
      "Train Epoch: 17 [0/3434 (0%)] Loss: 2.031880 time:126.00s\n",
      "Train Epoch: 17 [1280/3434 (37%)] Loss: 1.847891 time:128.00s\n",
      "Train Epoch: 17 [2560/3434 (74%)] Loss: 3.351691 time:129.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 17 Average loss: 2.8434\n",
      "Train Epoch: 18 [0/3434 (0%)] Loss: 2.868044 time:134.00s\n",
      "Train Epoch: 18 [1280/3434 (37%)] Loss: 1.802371 time:135.00s\n",
      "Train Epoch: 18 [2560/3434 (74%)] Loss: 2.206102 time:137.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 18 Average loss: 2.7526\n",
      "Train Epoch: 19 [0/3434 (0%)] Loss: 3.469604 time:141.00s\n",
      "Train Epoch: 19 [1280/3434 (37%)] Loss: 1.306775 time:142.00s\n",
      "Train Epoch: 19 [2560/3434 (74%)] Loss: 2.115960 time:144.00s\n",
      "Save Best Model!\n",
      "====> Epoch: 19 Average loss: 2.5023\n"
     ]
    }
   ],
   "source": [
    "train_loss11 = open('./train_proces/train_'+str(num_var)+'_'+str(k)+'.txt', 'w')\n",
    "train_data = MyDataset(datatxt='train_tal.txt', transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=True,num_workers=20)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "strattime = datetime.datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img,oimg,_ = data\n",
    "        img = Variable(img)\n",
    "        img = img.to(device)\n",
    "        oimg = Variable(oimg)\n",
    "        oimg = oimg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, _ = model.encode(img)\n",
    "        omu, _ = model.encode(oimg)\n",
    "        loss = reconstruction_function(mu, omu)\n",
    "        loss.backward()\n",
    "        # train_loss += loss.data[0]\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            endtime = datetime.datetime.now()\n",
    "            asd = str('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} time:{:.2f}s'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(img),\n",
    "                (endtime-strattime).seconds))\n",
    "            print(asd)\n",
    "            train_loss11.write(asd+'\\n')\n",
    "            # torch.save(model, './model/b_vae'+str(epoch)+'_'+str(batch_idx)+'.pth')\n",
    "    if epoch == 0:\n",
    "        best_loss = train_loss / len(train_loader.dataset)\n",
    "    if epoch > 0 and best_loss > train_loss / len(train_loader.dataset):\n",
    "        best_loss = train_loss / len(train_loader.dataset)\n",
    "        asds = 'Save Best Model!'\n",
    "        print(asds)\n",
    "        train_loss11.write(asds+'\\n')\n",
    "        torch.save(model, './model/vae_'+str(num_var)+'_'+str(k)+'_best.pth')\n",
    "    asds = str('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))\n",
    "    print(asds)\n",
    "    train_loss11.write(asds+'\\n')\n",
    "train_loss11.close()\n",
    "# if epoch == num_epochs-1:\n",
    "#     torch.save(model, './model/vae_'+str(num_var)+'_'+str(k)+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e494c9-5898-4992-a3ff-b686d734aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.43it/s]\n",
      "/data/xqf/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3434\n"
     ]
    }
   ],
   "source": [
    "train_data = MyDataset(datatxt='train_tal.txt', transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size = batch_size, shuffle=False,num_workers=20)\n",
    "\n",
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('./result')\n",
    "model.eval()\n",
    "from tqdm import tqdm\n",
    "sssi = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "        img,oimg,fn = data\n",
    "        img = Variable(img)\n",
    "        img = img.to(device)\n",
    "        oimg = Variable(oimg)\n",
    "        oimg = oimg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, _ = model.encode(img)\n",
    "        omu, _ = model.encode(oimg)\n",
    "\n",
    "        for i in range(len(img)):\n",
    "            qw = [fn[0][i]]\n",
    "            qw.extend(mu[i].cpu().detach().numpy())\n",
    "            qw.extend(fn[1][i])\n",
    "            qw.extend(omu[i].cpu().detach().numpy())\n",
    "            sssi.append(qw)\n",
    "\n",
    "    dd = np.array(sssi)\n",
    "    print(len(dd))\n",
    "    # np.save(pt+'result_ssim.npy',dd)\n",
    "    np.save('./result/resu_'+str(num_var)+'_'+str(k)+'_all.npy',dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac87a1-83ff-4fe4-8401-62b8e6cc8ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
